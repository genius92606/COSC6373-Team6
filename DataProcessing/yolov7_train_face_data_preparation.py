# -*- coding: utf-8 -*-
"""YoLov7_train_face_data_preparation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-oRt8EuGNP8xVp-7hGI_gBPqL-kPBDb

Download WilderFace Dataset
"""

import torchvision.datasets as datasets
from torchvision.transforms import ToTensor
import os
train_data = datasets.WIDERFace(
    root = 'data',
    split = 'train',                         
    transform = ToTensor(), 
    download = True        
)
val_data = datasets.WIDERFace(
    root = 'data', 
    split = 'val', 
    transform = ToTensor(),
    download = True
)
test_data = datasets.WIDERFace(
    root = 'data', 
    split = 'test', 
    transform = ToTensor(),
    download = True
)

"""Creating the WilderFace Dataset YAML File for Yolov7 fine tuning
[prepare-dataset-for-yolov5](https://docs.ultralytics.com/yolov5/train_custom_data/#13-prepare-dataset-for-yolov5)
"""

with open(os.getcwd() + '/data/widerface/widerface.yaml','x') as f:
  f.write("# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]" + os.linesep)
  f.write("train: train/images/  # train images" + os.linesep)
  f.write("val: val/images/  # val images" + os.linesep)
  f.write(os.linesep)
  f.write("# number of classes" + os.linesep)
  f.write("nc: 1")
  f.write(os.linesep)
  f.write("# class names" + os.linesep)
  f.write("names: ['face']" + os.linesep)
  f.close()


"""one *.txt file per image (if no objects in image, no *.txt file is required). The *.txt file specifications are:

One row per object
Each row is class x_center y_center width height format.
Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.
Class numbers are zero-indexed (start from 0).

Process label and images
"""

import shutil
import cv2
import os
#functions are adapted from https://github.com/deepcam-cn/yolov5-face/blob/master/data/val2yolo_for_test.py
#convert frow xywh to xxyy box representation
def xywh2xxyy(box):
    x1 = box[0]
    y1 = box[1]
    x2 = box[0] + box[2]
    y2 = box[1] + box[3]
    return (x1, x2, y1, y2)

#convert to yolo box
def convert(size, box):
    dw = 1. / (size[0])
    dh = 1. / (size[1])
    x = (box[0] + box[1]) / 2.0 - 1
    y = (box[2] + box[3]) / 2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    return (x, y, w, h)

def widerface2yolo(img_info,name):
  if name == 'train':
    out_path = 'data/widerface/train/{}/{}'
  else:
    out_path = 'data/widerface/val/{}/{}'
  
  out_path_dir = out_path[:out_path.find('/{')]
  if not os.path.exists(out_path_dir):
    # Create a new directory
    os.makedirs(out_path_dir+'/images')
    os.makedirs(out_path_dir+'/labels')
  for info in img_info:
    img_path = info['img_path']
    img_name = os.path.basename(img_path)
    #copy image to the new path
    out_img = out_path.format('images',img_name)
    shutil.copy(img_path, out_img)

    #create label txt for yolo
    out_txt = out_path.format('labels',os.path.splitext(img_name)[0]+'.txt')
    bboxs = info['annotations']['bbox'].numpy().tolist()
    f = open(out_txt, 'w')
    img = cv2.imread(img_path)
    height, width, _ = img.shape
    for box in bboxs:
      box = convert((width, height), xywh2xxyy(box))
      label = '0 {} {} {} {}'.format(round(box[0], 4), round(box[1], 4), round(box[2], 4), round(box[3], 4))
      f.write(label + '\n')
    f.close()

widerface2yolo(train_data.img_info,'train')
widerface2yolo(val_data.img_info,'val')


